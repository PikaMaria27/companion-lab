{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b5a31a-5634-4ab9-ad2e-848adbebf274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.09861229 -0.40546511]\n",
      "[[-2.87682072e-01 -1.38629436e+00 -1.38629436e+00]\n",
      " [-2.51052925e+01 -1.24997790e-11 -6.93147181e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Ex. 1 ----------------------------------------------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "\n",
    "# Create the training set\n",
    "features = ['study', 'free', 'money']\n",
    "target = 'is_spam'\n",
    "messages = pd.DataFrame(\n",
    "[(1, 0, 0, 0),\n",
    "(0, 0, 1, 0),\n",
    "(1, 0, 0, 0),\n",
    "(1, 1, 0, 0)] +\n",
    "[(0, 1, 0, 1)] * 4 +\n",
    "[(0, 1, 1, 1)] * 4,\n",
    "columns=features+[target])\n",
    "\n",
    "# Create the prediction set\n",
    "X = messages[features]\n",
    "y = messages[target]\n",
    "cl = BernoulliNB(alpha=1e-10).fit(X, y)\n",
    "\n",
    "print(cl.class_log_prior_)\n",
    "print(cl.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4585397c-e310-4c41-866d-9053ef1865f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_log_prior with no smoothing: -1.0986122886681098, -0.40546510810816444\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "def class_log_prior_calculator(messages):\n",
    "    y = messages[target]\n",
    "    prob_0 = 0\n",
    "    prob_1 = 0\n",
    "    for element in y:\n",
    "        if element == 0:\n",
    "            prob_0 += 1 \n",
    "        elif element == 1:\n",
    "            prob_1 += 1\n",
    "    prob_0 = prob_0 / len(y)\n",
    "    prob_1 = prob_1 / len(y)\n",
    "    print(f\"class_log_prior with no smoothing: {np.log(prob_0)}, {np.log(prob_1)}\")\n",
    "\n",
    "class_log_prior_calculator(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f868be0-78b0-48d5-a4b1-26268ec63658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_log_prob with no smoothing: -0.2876820724517809, -1.3862943611198906, -1.3862943611198906, -inf, 0.0, -0.6931471805599453 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\AppData\\Local\\Temp\\ipykernel_17220\\2666171953.py:36: RuntimeWarning: divide by zero encountered in log\n",
      "  print(f\"feature_log_prob with no smoothing: {np.log(study_spam/y_is_0)}, {np.log(free_spam/y_is_0)}, {np.log(money_spam/y_is_0)}, {np.log(study_not_spam/y_is_1)}, {np.log(free_not_spam/y_is_1)}, {np.log(money_not_spam/y_is_1)} \")\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def feature_log_prob_calculator(messages):\n",
    "    features = messages.columns[:-1]  # Assuming the target variable is the last column\n",
    "    target_column = messages.columns[-1]\n",
    "\n",
    "    study_spam = 0\n",
    "    study_not_spam = 0\n",
    "    free_spam = 0\n",
    "    free_not_spam = 0\n",
    "    money_spam = 0\n",
    "    money_not_spam = 0\n",
    "    y_is_0 = 0\n",
    "    y_is_1 = 0\n",
    "\n",
    "    for i in range(len(messages)):\n",
    "        if messages[target_column][i] == 0:\n",
    "            y_is_0 += 1\n",
    "            if messages[features[0]][i] == 1:\n",
    "                study_spam += 1\n",
    "            if messages[features[1]][i] == 1:\n",
    "                free_spam += 1\n",
    "            if messages[features[2]][i] == 1:\n",
    "                money_spam += 1\n",
    "        elif messages[target_column][i] == 1:\n",
    "            y_is_1 += 1\n",
    "            if messages[features[0]][i] == 1:\n",
    "                study_not_spam += 1\n",
    "            if messages[features[1]][i] == 1:\n",
    "                free_not_spam += 1\n",
    "            if messages[features[2]][i] == 1:\n",
    "                money_not_spam += 1\n",
    "\n",
    "    print(f\"feature_log_prob with no smoothing: {np.log(study_spam/y_is_0)}, {np.log(free_spam/y_is_0)}, {np.log(money_spam/y_is_0)}, {np.log(study_not_spam/y_is_1)}, {np.log(free_not_spam/y_is_1)}, {np.log(money_not_spam/y_is_1)} \")\n",
    "\n",
    "feature_log_prob_calculator(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19c3500f-1118-4771-a1db-111fb1321ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex. 3 ----------------------------------------------------------------------------------------------------------------------\n",
    "# a)\n",
    "import pandas as pd\n",
    "from tools.pd_helpers import apply_counts\n",
    "\n",
    "d = pd.DataFrame({'X1': [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "                  'X2': [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                  'C' : [2, 18, 4, 1, 4, 1, 2, 18],\n",
    "                  'Y' : [0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "d=apply_counts(d, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27083f7d-1146-4fc3-90ff-d4befcb450e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliJB:\n",
    "    def fitJB(self, X, y):\n",
    "        self.classes, y_counts = np.unique(y, return_counts=True)\n",
    "        self.class_probs = y_counts / len(y)\n",
    "        \n",
    "        self.feature_probs = {}\n",
    "        for c in self.classes:\n",
    "            class_data = X[y == c]\n",
    "            feature_probs_c = class_data.sum(axis=0) / len(class_data)\n",
    "            self.feature_probs[c] = feature_probs_c\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for c in self.classes:\n",
    "            probs_c = self.class_probs[c] * np.prod(X * self.feature_probs[c] + (1 - X) * (1 - self.feature_probs[c]), axis=1)\n",
    "            probabilities.append(probs_c)\n",
    "        \n",
    "        probabilities = np.array(probabilities).T\n",
    "        probabilities /= probabilities.sum(axis=1, keepdims=True)\n",
    "        \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a559a84-6f88-4293-969c-ae33cb352054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint Bayes estimates 2^(n+1) - 1 probabilities, where n is the number of input attributes.\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "print(\"Joint Bayes estimates 2^(n+1) - 1 probabilities, where n is the number of input attributes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23394e5f-bd0f-4393-b53a-fda2af7d7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24 0.76]]\n"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "jb_model = BernoulliJB()\n",
    "\n",
    "X_train = d[['X1', 'X2']].values\n",
    "y_train = d['Y'].values\n",
    "\n",
    "jb_model.fitJB(X_train, y_train)\n",
    "X_instance = np.array([[0, 0]])\n",
    "proba_instance = jb_model.predict_proba(X_instance)\n",
    "print(proba_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "270185e9-2b7b-4f0f-81c3-df0cb8ceec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24 0.76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\naive_bayes.py:624: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "c:\\users\\maria\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\naive_bayes.py:633: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# d)\n",
    "nb_model = BernoulliNB(alpha=0) \n",
    "nb_model.fit(X_train, y_train)\n",
    "X_instance = np.array([[0, 0]])\n",
    "proba_instance_nb = nb_model.predict_proba(X_instance)\n",
    "\n",
    "print(proba_instance_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
